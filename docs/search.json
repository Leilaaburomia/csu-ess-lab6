[
  {
    "objectID": "lab6.html",
    "href": "lab6.html",
    "title": "lab 6",
    "section": "",
    "text": "# Lab Set Up\n\n\nlibrary(tidyverse)\n\nWarning: package 'tidyverse' was built under R version 4.4.2\n\n\nWarning: package 'readr' was built under R version 4.4.2\n\n\nWarning: package 'purrr' was built under R version 4.4.3\n\n\nWarning: package 'forcats' was built under R version 4.4.2\n\n\nWarning: package 'lubridate' was built under R version 4.4.2\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tidymodels)\n\nWarning: package 'tidymodels' was built under R version 4.4.3\n\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.3.0 ──\n✔ broom        1.0.8     ✔ rsample      1.2.1\n✔ dials        1.4.0     ✔ tune         1.3.0\n✔ infer        1.0.7     ✔ workflows    1.2.0\n✔ modeldata    1.4.0     ✔ workflowsets 1.1.0\n✔ parsnip      1.3.1     ✔ yardstick    1.3.2\n✔ recipes      1.2.1     \n\n\nWarning: package 'broom' was built under R version 4.4.3\n\n\nWarning: package 'dials' was built under R version 4.4.3\n\n\nWarning: package 'infer' was built under R version 4.4.2\n\n\nWarning: package 'modeldata' was built under R version 4.4.2\n\n\nWarning: package 'parsnip' was built under R version 4.4.3\n\n\nWarning: package 'recipes' was built under R version 4.4.3\n\n\nWarning: package 'rsample' was built under R version 4.4.2\n\n\nWarning: package 'tune' was built under R version 4.4.3\n\n\nWarning: package 'workflows' was built under R version 4.4.3\n\n\nWarning: package 'workflowsets' was built under R version 4.4.2\n\n\nWarning: package 'yardstick' was built under R version 4.4.2\n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n\nlibrary(powerjoin)\n\nWarning: package 'powerjoin' was built under R version 4.4.3\n\nlibrary(glue)\nlibrary(vip)\n\nWarning: package 'vip' was built under R version 4.4.3\n\n\n\nAttaching package: 'vip'\n\nThe following object is masked from 'package:utils':\n\n    vi\n\nlibrary(baguette)\n\nWarning: package 'baguette' was built under R version 4.4.3\n\nlibrary(purrr)\nlibrary(ggplot2)\nlibrary(ggpubr)\n\nWarning: package 'ggpubr' was built under R version 4.4.3\n\n# Data Download \nroot  &lt;- 'https://gdex.ucar.edu/dataset/camels/file'\n\n# Documentation PDF\ndownload.file('https://gdex.ucar.edu/dataset/camels/file/camels_attributes_v2.0.pdf', \n              'data/camels_attributes_v2.0.pdf')\n\n# a. Basin characteristics\ntypes &lt;- c(\"clim\", \"geol\", \"soil\", \"topo\", \"vege\", \"hydro\")\n\n# b. Where the files live online ...\nremote_files  &lt;- glue('{root}/camels_{types}.txt')\n# b. where we want to download the data ...\nlocal_files   &lt;- glue('data/camels_{types}.txt')\n\n# c. \nwalk2(remote_files, local_files, download.file, quiet = TRUE)\n\n# d. Read and merge data\ncamels &lt;- map(local_files, read_delim, show_col_types = FALSE)\n\n# e. merge tables \nlibrary(powerjoin)\ncamels &lt;- power_full_join(camels ,by = 'gauge_id')\n\nZero_q_freq is the frequency of days where discharge equals 0 mm/day (Q = 0 mm/day). It is measured in percentage."
  },
  {
    "objectID": "lab6.html#question-1.-download-data",
    "href": "lab6.html#question-1.-download-data",
    "title": "lab 6",
    "section": "",
    "text": "# Lab Set Up\n\n\nlibrary(tidyverse)\n\nWarning: package 'tidyverse' was built under R version 4.4.2\n\n\nWarning: package 'readr' was built under R version 4.4.2\n\n\nWarning: package 'purrr' was built under R version 4.4.3\n\n\nWarning: package 'forcats' was built under R version 4.4.2\n\n\nWarning: package 'lubridate' was built under R version 4.4.2\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tidymodels)\n\nWarning: package 'tidymodels' was built under R version 4.4.3\n\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.3.0 ──\n✔ broom        1.0.8     ✔ rsample      1.2.1\n✔ dials        1.4.0     ✔ tune         1.3.0\n✔ infer        1.0.7     ✔ workflows    1.2.0\n✔ modeldata    1.4.0     ✔ workflowsets 1.1.0\n✔ parsnip      1.3.1     ✔ yardstick    1.3.2\n✔ recipes      1.2.1     \n\n\nWarning: package 'broom' was built under R version 4.4.3\n\n\nWarning: package 'dials' was built under R version 4.4.3\n\n\nWarning: package 'infer' was built under R version 4.4.2\n\n\nWarning: package 'modeldata' was built under R version 4.4.2\n\n\nWarning: package 'parsnip' was built under R version 4.4.3\n\n\nWarning: package 'recipes' was built under R version 4.4.3\n\n\nWarning: package 'rsample' was built under R version 4.4.2\n\n\nWarning: package 'tune' was built under R version 4.4.3\n\n\nWarning: package 'workflows' was built under R version 4.4.3\n\n\nWarning: package 'workflowsets' was built under R version 4.4.2\n\n\nWarning: package 'yardstick' was built under R version 4.4.2\n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n\nlibrary(powerjoin)\n\nWarning: package 'powerjoin' was built under R version 4.4.3\n\nlibrary(glue)\nlibrary(vip)\n\nWarning: package 'vip' was built under R version 4.4.3\n\n\n\nAttaching package: 'vip'\n\nThe following object is masked from 'package:utils':\n\n    vi\n\nlibrary(baguette)\n\nWarning: package 'baguette' was built under R version 4.4.3\n\nlibrary(purrr)\nlibrary(ggplot2)\nlibrary(ggpubr)\n\nWarning: package 'ggpubr' was built under R version 4.4.3\n\n# Data Download \nroot  &lt;- 'https://gdex.ucar.edu/dataset/camels/file'\n\n# Documentation PDF\ndownload.file('https://gdex.ucar.edu/dataset/camels/file/camels_attributes_v2.0.pdf', \n              'data/camels_attributes_v2.0.pdf')\n\n# a. Basin characteristics\ntypes &lt;- c(\"clim\", \"geol\", \"soil\", \"topo\", \"vege\", \"hydro\")\n\n# b. Where the files live online ...\nremote_files  &lt;- glue('{root}/camels_{types}.txt')\n# b. where we want to download the data ...\nlocal_files   &lt;- glue('data/camels_{types}.txt')\n\n# c. \nwalk2(remote_files, local_files, download.file, quiet = TRUE)\n\n# d. Read and merge data\ncamels &lt;- map(local_files, read_delim, show_col_types = FALSE)\n\n# e. merge tables \nlibrary(powerjoin)\ncamels &lt;- power_full_join(camels ,by = 'gauge_id')\n\nZero_q_freq is the frequency of days where discharge equals 0 mm/day (Q = 0 mm/day). It is measured in percentage."
  },
  {
    "objectID": "lab6.html#question-2.-make-2-maps",
    "href": "lab6.html#question-2.-make-2-maps",
    "title": "lab 6",
    "section": "Question 2. Make 2 Maps",
    "text": "Question 2. Make 2 Maps\n\n# map colored by aridity \np_aridity &lt;- ggplot(data = camels, aes(x = gauge_lon, y = gauge_lat)) +\n  borders(\"state\", colour = \"gray40\") +\n  geom_point(aes(color = aridity)) +\n  scale_color_gradient(low = \"lightgreen\", high = \"maroon\") +\n  ggthemes::theme_map() +\n  theme(legend.title = element_text(size = 7)) +\n  labs(color = \"Aridity (PET/P)\")\n  \n\n# map colored by p_mean\np_p_mean &lt;- ggplot(data = camels, aes(x = gauge_lon, y = gauge_lat)) +\n  borders(\"state\", colour = \"gray40\") +\n  geom_point(aes(color = p_mean)) +\n  scale_color_gradient(low = \"yellow\", high = \"blue3\") +\n  ggthemes::theme_map() +\n  theme(legend.title = element_text(size = 7)) +\n  labs(color = \"Mean Precipitation (mm/day)\")\n \n\n\ncombined_plot &lt;- ggarrange(p_aridity, p_p_mean, ncol = 2, nrow = 1)\n\n\nannotate_figure(combined_plot, top = text_grob(\"Aridity and Mean Daily Precipitation Across the U.S.\", face = \"bold\", size = 14))\n\n\n\n\n\n\n\n\n\nModel Preparation\n\ncamels %&gt;%\n  select(aridity, p_mean, q_mean) %&gt;%\n  drop_na() %&gt;%\n  cor()\n\n           aridity     p_mean     q_mean\naridity  1.0000000 -0.7550090 -0.5817771\np_mean  -0.7550090  1.0000000  0.8865757\nq_mean  -0.5817771  0.8865757  1.0000000\n\n\n\n\nVisual EDA\n\n# Create a scatter plot of aridity vs rainfall\nggplot(camels, aes(x = aridity, y = p_mean)) +\n  # Add points colored by mean flow\n  geom_point(aes(color = q_mean)) +\n  # Add a linear regression line\n  geom_smooth(method = \"lm\", color = \"red\", linetype = 2) +\n  # Apply the viridis color scale\n  scale_color_viridis_c() +\n  # Add a title, axis labels, and theme (w/ legend on the bottom)\n  theme_linedraw() + \n  theme(legend.position = \"bottom\") + \n  labs(title = \"Aridity vs Rainfall vs Runnoff\", \n       x = \"Aridity\", \n       y = \"Rainfall\",\n       color = \"Mean Flow\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n## log-log relationship between aridity and rainfall is more linear\nggplot(camels, aes(x = aridity, y = p_mean)) +\n  geom_point(aes(color = q_mean)) +\n  geom_smooth(method = \"lm\") +\n  scale_color_viridis_c() +\n  # Apply log transformations to the x and y axes\n  scale_x_log10() + \n  scale_y_log10() +\n  theme_linedraw() +\n  theme(legend.position = \"bottom\") + \n  labs(title = \"Aridity vs Rainfall vs Runnoff\", \n       x = \"Aridity\", \n       y = \"Rainfall\",\n       color = \"Mean Flow\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n# visualize how a log transform may benefit the q_mean data\nggplot(camels, aes(x = aridity, y = p_mean)) +\n  geom_point(aes(color = q_mean)) +\n  geom_smooth(method = \"lm\") +\n  # Apply a log transformation to the color scale\n  scale_color_viridis_c(trans = \"log\") +\n  scale_x_log10() + \n  scale_y_log10() +\n  theme_linedraw() +\n  theme(legend.position = \"bottom\",\n        # Expand the legend width ...\n        legend.key.width = unit(2.5, \"cm\"),\n        legend.key.height = unit(.5, \"cm\")) + \n  labs(title = \"Aridity vs Rainfall vs Runnoff\", \n       x = \"Aridity\", \n       y = \"Rainfall\",\n       color = \"Mean Flow\") \n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\nModel Building\n\nlibrary(tidymodels)\n# 1. Split Data\nset.seed(123)\n# Bad form to perform simple transformations on the outcome variable within a \n# recipe. So, we'll do it here.\ncamels &lt;- camels |&gt; \n  mutate(logQmean = log(q_mean))\n# Generate the split\ncamels_split &lt;- initial_split(camels, prop = 0.8)\ncamels_train &lt;- training(camels_split)\ncamels_test  &lt;- testing(camels_split)\ncamels_cv &lt;- vfold_cv(camels_train, v = 10)\n\n\n# Create a recipe to preprocess the data\nrec &lt;-  recipe(logQmean ~ aridity + p_mean, data = camels_train) %&gt;%\n  # Log transform the predictor variables (aridity and p_mean)\n  step_log(all_predictors()) %&gt;%\n  # Add an interaction term between aridity and p_mean\n  step_interact(terms = ~ aridity:p_mean) |&gt; \n  # Drop any rows with missing values in the pred\n  step_naomit(all_predictors(), all_outcomes())\n# Prepare the data\nbaked_data &lt;- prep(rec, camels_train) |&gt; \n  bake(new_data = NULL)\n# Interaction with lm\n#  Base lm sets interaction terms with the * symbol\nlm_base &lt;- lm(logQmean ~ aridity * p_mean, data = baked_data)\nsummary(lm_base)\n\n\nCall:\nlm(formula = logQmean ~ aridity * p_mean, data = baked_data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.91162 -0.21601 -0.00716  0.21230  2.85706 \n\nCoefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    -1.77586    0.16365 -10.852  &lt; 2e-16 ***\naridity        -0.88397    0.16145  -5.475 6.75e-08 ***\np_mean          1.48438    0.15511   9.570  &lt; 2e-16 ***\naridity:p_mean  0.10484    0.07198   1.457    0.146    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5696 on 531 degrees of freedom\nMultiple R-squared:  0.7697,    Adjusted R-squared:  0.7684 \nF-statistic: 591.6 on 3 and 531 DF,  p-value: &lt; 2.2e-16\n\ntest_data &lt;-  bake(prep(rec), new_data = camels_test)\ntest_data$lm_pred &lt;- predict(lm_base, newdata = test_data)\n\n\n\nModel Evaluation: statistical and visual\n\n# Method is error prone and worthless if wanted to test a different algorithm. \nmetrics(test_data, truth = logQmean, estimate = lm_pred)\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       0.583\n2 rsq     standard       0.742\n3 mae     standard       0.390\n\nggplot(test_data, aes(x = logQmean, y = lm_pred, colour = aridity)) +\n  # Apply a gradient color scale\n  scale_color_gradient2(low = \"brown\", mid = \"orange\", high = \"darkgreen\") +\n  geom_point() +\n  geom_abline(linetype = 2) +\n  theme_linedraw() + \n  labs(title = \"Linear Model: Observed vs Predicted\",\n       x = \"Observed Log Mean Flow\",\n       y = \"Predicted Log Mean Flow\",\n       color = \"Aridity\")\n\n\n\n\n\n\n\n\n\n\nUsing a workflow instead\n\n# Define model\nlm_model &lt;- linear_reg() %&gt;%\n  # define the engine\n  set_engine(\"lm\") %&gt;%\n  # define the mode\n  set_mode(\"regression\")\n# Instantiate a workflow ...\nlm_wf &lt;- workflow() %&gt;%\n  # Add the recipe\n  add_recipe(rec) %&gt;%\n  # Add the model\n  add_model(lm_model) %&gt;%\n  # Fit the model to the training data\n  fit(data = camels_train) \n# Extract the model coefficients from the workflow\nsummary(extract_fit_engine(lm_wf))$coefficients\n\n                   Estimate Std. Error    t value     Pr(&gt;|t|)\n(Intercept)      -1.7758557 0.16364755 -10.851710 6.463654e-25\naridity          -0.8839738 0.16144589  -5.475357 6.745512e-08\np_mean            1.4843771 0.15511117   9.569762 4.022500e-20\naridity_x_p_mean  0.1048449 0.07198145   1.456555 1.458304e-01\n\n# replicate the results from the Lm_base model\n# From the base implementation\nsummary(lm_base)$coefficients\n\n                 Estimate Std. Error    t value     Pr(&gt;|t|)\n(Intercept)    -1.7758557 0.16364755 -10.851710 6.463654e-25\naridity        -0.8839738 0.16144589  -5.475357 6.745512e-08\np_mean          1.4843771 0.15511117   9.569762 4.022500e-20\naridity:p_mean  0.1048449 0.07198145   1.456555 1.458304e-01\n\n# Making predictions on the test data\nlm_data &lt;- augment(lm_wf, new_data = camels_test)\ndim(lm_data)\n\n[1] 135  61\n\n\n\n\n2nd Model Evaluation: statistical and visual\n\n# statistical\nmetrics(lm_data, truth = logQmean, estimate = .pred)\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       0.583\n2 rsq     standard       0.742\n3 mae     standard       0.390\n\n# Visual\nggplot(lm_data, aes(x = logQmean, y = .pred, colour = aridity)) +\n  scale_color_viridis_c() +\n  geom_point() +\n  geom_abline() +\n  theme_linedraw()\n\n\n\n\n\n\n\n\n\n\nAdvantage of Approach: can easily switch\n\nlibrary(baguette)\nrf_model &lt;- rand_forest() %&gt;%\n  set_engine(\"ranger\", importance = \"impurity\") %&gt;%\n  set_mode(\"regression\")\nrf_wf &lt;- workflow() %&gt;%\n  add_recipe(rec) %&gt;%\n  # Add the model\n  add_model(rf_model) %&gt;%\n  # Fit the model\n  fit(data = camels_train) \n# Predictions on the test data\nrf_data &lt;- augment(rf_wf, new_data = camels_test)\ndim(rf_data)\n\n[1] 135  60\n\n# evaluate data and visual the observed vs predicted values colored by aridity\nmetrics(rf_data, truth = logQmean, estimate = .pred)\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       0.596\n2 rsq     standard       0.733\n3 mae     standard       0.370\n\nggplot(rf_data, aes(x = logQmean, y = .pred, colour = aridity)) +\n  scale_color_viridis_c() +\n  geom_point() +\n  geom_abline() +\n  theme_linedraw()\n\n\n\n\n\n\n\n# workflowset approach \nwf &lt;- workflow_set(list(rec), list(lm_model, rf_model)) %&gt;%\n  workflow_map('fit_resamples', resamples = camels_cv)\n\nWarning: package 'ranger' was built under R version 4.4.3\n\nautoplot(wf)\n\n\n\n\n\n\n\nrank_results(wf, rank_metric = \"rsq\", select_best = TRUE)\n\n# A tibble: 4 × 9\n  wflow_id          .config .metric  mean std_err     n preprocessor model  rank\n  &lt;chr&gt;             &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;        &lt;chr&gt; &lt;int&gt;\n1 recipe_rand_fore… Prepro… rmse    0.565  0.0243    10 recipe       rand…     1\n2 recipe_rand_fore… Prepro… rsq     0.770  0.0255    10 recipe       rand…     1\n3 recipe_linear_reg Prepro… rmse    0.569  0.0260    10 recipe       line…     2\n4 recipe_linear_reg Prepro… rsq     0.770  0.0223    10 recipe       line…     2"
  },
  {
    "objectID": "lab6.html#question-3.-build-a-xgboost-and-neural-network-model",
    "href": "lab6.html#question-3.-build-a-xgboost-and-neural-network-model",
    "title": "lab 6",
    "section": "Question 3. Build a xgboost and neural network model",
    "text": "Question 3. Build a xgboost and neural network model\nXgboost regression model using Boost_tree:\n\nlibrary(workflows)\nlibrary(dplyr)\nlibrary(parsnip)\nlibrary(xgboost)\n\nWarning: package 'xgboost' was built under R version 4.4.3\n\n\n\nAttaching package: 'xgboost'\n\n\nThe following object is masked from 'package:dplyr':\n\n    slice\n\n# model definition \nbt_model &lt;- boost_tree() %&gt;%\n  set_engine(\"xgboost\") %&gt;%\n  set_mode(\"regression\")\n# workflow\nbt_wf &lt;- workflow() %&gt;%\n  add_recipe(rec) %&gt;%\n  add_model(bt_model) %&gt;%\n  fit(data = camels_train)\n# Making predictions \nbt_data &lt;- augment(bt_wf, new_data = camels_test)\ndim(bt_data)\n\n[1] 135  60\n\n# Model Evaluations\nmetrics(bt_data, truth = logQmean, estimate = .pred)\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       0.631\n2 rsq     standard       0.702\n3 mae     standard       0.397\n\nggplot(bt_data, aes(x = logQmean, y = .pred, colour = aridity)) +\n  scale_color_viridis_c() +\n  geom_point() +\n  geom_abline() +\n  theme_linedraw()\n\n\n\n\n\n\n\n\nNeural Network Model using nnet engine:\n\nlibrary(nnet)\n\nWarning: package 'nnet' was built under R version 4.4.3\n\nlibrary(baguette)\n\n# model definition\nmlp_model &lt;- bag_mlp() %&gt;%\n  set_engine(\"nnet\", times = 10) %&gt;%\n  set_mode(\"regression\")\n# workflow\nmlp_wf &lt;- workflow() %&gt;%\n  add_recipe(rec) %&gt;%\n  add_model(mlp_model) %&gt;%\n  fit(data = camels_train)\n\n# Making predictions\nmlp_data &lt;- augment(mlp_wf, new_data = camels_test)\ndim(mlp_data)\n\n[1] 135  61\n\n# Model Evaluation\nmetrics(mlp_data, truth = logQmean, estimate = .pred)\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       0.553\n2 rsq     standard       0.766\n3 mae     standard       0.339\n\nggplot(mlp_data, aes(x = logQmean, y = .pred, colour = aridity)) +\n  scale_color_viridis_c() +\n  geom_point() +\n  geom_abline() +\n  theme_linedraw()\n\n\n\n\n\n\n\n\nComparing models using a workflow set:\n\nwf2 &lt;- workflow_set(list(rec), list(lm_model, rf_model, bt_model, mlp_model)) %&gt;%\n  workflow_map('fit_resamples', resamples = camels_cv)\n\nautoplot(wf2)\n\n\n\n\n\n\n\nrank_results(wf2, rank_metric = \"rsq\", select_best = TRUE)\n\n# A tibble: 8 × 9\n  wflow_id          .config .metric  mean std_err     n preprocessor model  rank\n  &lt;chr&gt;             &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;        &lt;chr&gt; &lt;int&gt;\n1 recipe_bag_mlp    Prepro… rmse    0.544  0.0289    10 recipe       bag_…     1\n2 recipe_bag_mlp    Prepro… rsq     0.789  0.0249    10 recipe       bag_…     1\n3 recipe_rand_fore… Prepro… rmse    0.562  0.0251    10 recipe       rand…     2\n4 recipe_rand_fore… Prepro… rsq     0.773  0.0259    10 recipe       rand…     2\n5 recipe_linear_reg Prepro… rmse    0.569  0.0260    10 recipe       line…     3\n6 recipe_linear_reg Prepro… rsq     0.770  0.0223    10 recipe       line…     3\n7 recipe_boost_tree Prepro… rmse    0.600  0.0289    10 recipe       boos…     4\n8 recipe_boost_tree Prepro… rsq     0.745  0.0268    10 recipe       boos…     4\n\n\nFrom the results of autoplot and rank_results I would move forward with the neural network model."
  },
  {
    "objectID": "lab6.html#question-4.-lm-pipeline-to-predict-mean-streamflow",
    "href": "lab6.html#question-4.-lm-pipeline-to-predict-mean-streamflow",
    "title": "lab 6",
    "section": "Question 4. LM Pipeline to predict mean streamflow",
    "text": "Question 4. LM Pipeline to predict mean streamflow\n\n4.a. Data Prep/Data Splitting\n\ncamels %&gt;%\n  select(high_prec_freq, q95, q_mean) %&gt;%\n  mutate(across(everything(), ~ ifelse(is.infinite(.), NA, .))) %&gt;%\n  drop_na()\n\n# A tibble: 670 × 3\n   high_prec_freq   q95 q_mean\n            &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n 1           13.0  6.37   1.70\n 2           20.6  7.12   2.17\n 3           17.2  6.85   1.82\n 4           18.9  8.01   2.03\n 5           20.1  8.10   2.18\n 6           13.5  8.67   2.41\n 7           17.5 10.1    2.73\n 8           19.2  8.44   2.28\n 9           20.4  6.87   1.82\n10           20.8  5.78   1.70\n# ℹ 660 more rows\n\nset.seed(932003)\n\ncamels_split2 &lt;- initial_split(camels, prop = 0.75)\ncamels_train2 &lt;- training(camels_split2)\ncamels_test2 &lt;- testing(camels_split2)\n\ncamels_cv2 &lt;- vfold_cv(camels_train2, v = 10)\n\n\ncamels %&gt;%\n  select(high_prec_freq, q95, q_mean) %&gt;%\n  drop_na() %&gt;%\n  cor()\n\n               high_prec_freq        q95     q_mean\nhigh_prec_freq      1.0000000 -0.6535573 -0.6687589\nq95                -0.6535573  1.0000000  0.9633320\nq_mean             -0.6687589  0.9633320  1.0000000\n\n\n\nggplot(camels, aes(x = high_prec_freq, y = q95)) +\n  geom_point(aes(color = q_mean)) +\n  geom_smooth(method = \"lm\", color = \"red\", linetype = 2) +\n  scale_color_viridis_c() +\n  theme_linedraw() + \n  theme(legend.position = \"bottom\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 1 row containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\n\n\n4.b. Recipe\n\nlibrary(tidymodels)\n\nflow_recipe &lt;- recipe(logQmean ~ high_prec_freq + q95, data = camels_train2) %&gt;%\n  step_naomit() %&gt;%\n  step_mutate(across(where(is.character), as.factor)) %&gt;%\n  step_mutate(across(where(is.factor), as.numeric))\n\nflow_recipe_prep &lt;- prep(flow_recipe, training = camels_train2)\n\nbaked_data2 &lt;- juice(flow_recipe_prep)\n\nsum(is.na(baked_data))\n\n[1] 0\n\nsum(is.infinite(as.matrix(baked_data)))\n\n[1] 0\n\n\nI have chosen this formula because both high_prec_freq and q95 are correlated with mean daily discharge but not as strongly correlated with each other. high precipitation frequency has a correlation coefficient of -0.67 and q95 has a correlation coefficient of 0.96. Additionally from the PDF, high_prec_freq is fairly likely to affect streamflow because the higher frequency of rainfall will increase the potential of this water to increase streamflow. Q95 is directly correlated with streamflow because it describes high flow and will contribute to the mean.\n\n\n4.c. Define 3 Models\n\nlibrary(baguette)\n\nforest_model &lt;- rand_forest() %&gt;%\n  set_engine(\"ranger\") %&gt;%\n  set_mode(\"regression\")\n\nforest_wf &lt;- workflow() %&gt;%\n  add_recipe(flow_recipe) %&gt;%\n  add_model(forest_model)\n\n\nlm_model &lt;- linear_reg() %&gt;%\n  set_engine(\"lm\") %&gt;%\n  set_mode(\"regression\")\n\nlm_wf &lt;- workflow() %&gt;%\n  add_recipe(flow_recipe) %&gt;%\n  add_model(lm_model)\n\n\nlibrary(parsnip)\nlibrary(xgboost)\n\nxg_model &lt;- boost_tree() %&gt;%\n  set_engine(\"xgboost\") %&gt;%\n  set_mode(\"regression\")\n\nxg_wf &lt;- workflow() %&gt;%\n  add_recipe(flow_recipe) %&gt;%\n  add_model(xg_model) \n\n\n\n4.d. Workflow Set\n\nwf3 &lt;- workflow_set(\n  preproc = list(flow_recipe), \n  models = list(forest = forest_model, lm = lm_model, xgboost = xg_model))\n\nresults &lt;- workflow_map(wf3, \"fit_resamples\", resamples = camels_cv2)\n\n\n\n4.e. Evaluation\n\nautoplot(results)\n\n\n\n\n\n\n\nrank_results(results, select_best = TRUE)\n\n# A tibble: 6 × 9\n  wflow_id       .config    .metric  mean std_err     n preprocessor model  rank\n  &lt;chr&gt;          &lt;chr&gt;      &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;        &lt;chr&gt; &lt;int&gt;\n1 recipe_forest  Preproces… rmse    0.291  0.0156    10 recipe       rand…     1\n2 recipe_forest  Preproces… rsq     0.934  0.0123    10 recipe       rand…     1\n3 recipe_xgboost Preproces… rmse    0.296  0.0241    10 recipe       boos…     2\n4 recipe_xgboost Preproces… rsq     0.935  0.0107    10 recipe       boos…     2\n5 recipe_lm      Preproces… rmse    0.760  0.0438    10 recipe       line…     3\n6 recipe_lm      Preproces… rsq     0.627  0.0181    10 recipe       line…     3\n\n\nThe Random Forest Model is best because it has a low ‘rmse’ and a high R^squared mean of .93. Additionally, the standard errors are less than other models.\n\n\n4.f. Extract and Evaluate\n\nforest_wf &lt;- workflow() %&gt;%\n  add_recipe(flow_recipe) %&gt;%\n  add_model(forest_model) %&gt;%\n  fit(data = camels_train2)\n\nforest_data &lt;- augment(forest_wf, new_data = camels_test2)\ndim(forest_data)\n\n[1] 168  60\n\n#&gt; [1] 168 60\nmetrics(forest_data, truth = logQmean, estimate = .pred)\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       0.259\n2 rsq     standard       0.941\n3 mae     standard       0.199\n\nggplot(forest_data, aes(x = logQmean, y = .pred, colour = high_prec_freq)) +\n  scale_color_gradient(low = \"orange3\", high = \"darkblue\") +\n  geom_point() +\n  geom_abline() +\n  theme_linedraw() +\n  labs(title = \"Random Forest Model: Observed vs Predicted Mean Streamflow\",\n       x = \"Observed Log Mean Flow\",\n       y = \"Predicted Log Mean Flow\",\n       color = \"High Precipitation Frequency (days/yr)\")\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nThe results of my predicted versus observed log mean streamflow show that the random forest model with high prec frequency and q95 as predictors does a good job predicting log mean streamflow. From the ggplot you can see that the slope is ~1 indicating that predicted is strongly positively correlated with observed. Additionally, you can see that the points are closely clustered around the line, showing significance of the results. From the points, you can also see that high precipitation frequency is positively correlated with log mean streamflow."
  },
  {
    "objectID": "hyperparameter-tuning.html",
    "href": "hyperparameter-tuning.html",
    "title": "Lab 8: Machine Learning Tuning",
    "section": "",
    "text": "library(tidyverse)\n\nWarning: package 'tidyverse' was built under R version 4.4.2\n\n\nWarning: package 'readr' was built under R version 4.4.2\n\n\nWarning: package 'purrr' was built under R version 4.4.3\n\n\nWarning: package 'forcats' was built under R version 4.4.2\n\n\nWarning: package 'lubridate' was built under R version 4.4.2\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tidymodels)\n\nWarning: package 'tidymodels' was built under R version 4.4.3\n\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.3.0 ──\n✔ broom        1.0.8     ✔ rsample      1.2.1\n✔ dials        1.4.0     ✔ tune         1.3.0\n✔ infer        1.0.7     ✔ workflows    1.2.0\n✔ modeldata    1.4.0     ✔ workflowsets 1.1.0\n✔ parsnip      1.3.1     ✔ yardstick    1.3.2\n✔ recipes      1.2.1     \n\n\nWarning: package 'broom' was built under R version 4.4.3\n\n\nWarning: package 'dials' was built under R version 4.4.3\n\n\nWarning: package 'infer' was built under R version 4.4.2\n\n\nWarning: package 'modeldata' was built under R version 4.4.2\n\n\nWarning: package 'parsnip' was built under R version 4.4.3\n\n\nWarning: package 'recipes' was built under R version 4.4.3\n\n\nWarning: package 'rsample' was built under R version 4.4.2\n\n\nWarning: package 'tune' was built under R version 4.4.3\n\n\nWarning: package 'workflows' was built under R version 4.4.3\n\n\nWarning: package 'workflowsets' was built under R version 4.4.2\n\n\nWarning: package 'yardstick' was built under R version 4.4.2\n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n\nlibrary(dplyr)\nlibrary(visdat)\n\nWarning: package 'visdat' was built under R version 4.4.3\n\nlibrary(powerjoin)\n\nWarning: package 'powerjoin' was built under R version 4.4.3\n\nlibrary(glue)\nlibrary(vip)\n\nWarning: package 'vip' was built under R version 4.4.3\n\n\n\nAttaching package: 'vip'\n\nThe following object is masked from 'package:utils':\n\n    vi\n\nlibrary(baguette)\n\nWarning: package 'baguette' was built under R version 4.4.3\n\nlibrary(purrr)\nlibrary(ggplot2)\nlibrary(ggpubr)\n\nWarning: package 'ggpubr' was built under R version 4.4.3"
  },
  {
    "objectID": "hyperparameter-tuning.html#build-3-candidate-models",
    "href": "hyperparameter-tuning.html#build-3-candidate-models",
    "title": "Lab 8: Machine Learning Tuning",
    "section": "Build 3 Candidate Models",
    "text": "Build 3 Candidate Models\n\nlibrary(baguette)\n\nforest_model2 &lt;- rand_forest() %&gt;%\n  set_engine(\"ranger\") %&gt;%\n  set_mode(\"regression\")\n\nforest_wf2 &lt;- workflow() %&gt;%\n  add_recipe(flow_recipe2) %&gt;%\n  add_model(forest_model2)\n\n\nlm_model2 &lt;- linear_reg() %&gt;%\n  set_engine(\"lm\") %&gt;%\n  set_mode(\"regression\")\n\nlm_wf2 &lt;- workflow() %&gt;%\n  add_recipe(flow_recipe2) %&gt;%\n  add_model(lm_model2)\n\n\nlibrary(parsnip)\nlibrary(xgboost)\n\nWarning: package 'xgboost' was built under R version 4.4.3\n\n\n\nAttaching package: 'xgboost'\n\n\nThe following object is masked from 'package:dplyr':\n\n    slice\n\nxg_model2 &lt;- boost_tree() %&gt;%\n  set_engine(\"xgboost\") %&gt;%\n  set_mode(\"regression\")\n\nxg_wf2 &lt;- workflow() %&gt;%\n  add_recipe(flow_recipe2) %&gt;%\n  add_model(xg_model2)"
  },
  {
    "objectID": "hyperparameter-tuning.html#test-the-models",
    "href": "hyperparameter-tuning.html#test-the-models",
    "title": "Lab 8: Machine Learning Tuning",
    "section": "Test the Models",
    "text": "Test the Models\n\nwf4 &lt;- workflow_set(\n  preproc = list(flow_recipe2), \n  models = list(forest2 = forest_model2, lm2 = lm_model2, xgboost2 = xg_model2))\n\nresults2 &lt;- workflow_map(wf4, \"fit_resamples\", resamples = cam_cv)\n\nWarning: package 'ranger' was built under R version 4.4.3\n\nautoplot(results2)\n\n\n\n\n\n\n\nrank_results(results2, select_best = TRUE)\n\n# A tibble: 6 × 9\n  wflow_id        .config   .metric  mean std_err     n preprocessor model  rank\n  &lt;chr&gt;           &lt;chr&gt;     &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;        &lt;chr&gt; &lt;int&gt;\n1 recipe_lm2      Preproce… rmse    0.397 0.0248     10 recipe       line…     1\n2 recipe_lm2      Preproce… rsq     0.935 0.0101     10 recipe       line…     1\n3 recipe_forest2  Preproce… rmse    0.436 0.0268     10 recipe       rand…     2\n4 recipe_forest2  Preproce… rsq     0.925 0.00821    10 recipe       rand…     2\n5 recipe_xgboost2 Preproce… rmse    0.465 0.0189     10 recipe       boos…     3\n6 recipe_xgboost2 Preproce… rsq     0.916 0.00999    10 recipe       boos…     3\n\nforest_wf2 &lt;- workflow() %&gt;%\n  add_recipe(flow_recipe2) %&gt;%\n  add_model(forest_model2) %&gt;%\n  fit(data = camels_training)\n\nforest_data2 &lt;- augment(forest_wf2, new_data = camels_testing)\ndim(forest_data2)\n\n[1] 135  59\n\n#&gt; [1] 168 60\nmetrics(forest_data2, truth = q_mean, estimate = .pred)\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       0.492\n2 rsq     standard       0.917\n3 mae     standard       0.287"
  },
  {
    "objectID": "hyperparameter-tuning.html#model-selection",
    "href": "hyperparameter-tuning.html#model-selection",
    "title": "Lab 8: Machine Learning Tuning",
    "section": "Model Selection",
    "text": "Model Selection\nThe Random Forest Model is best because it has a low ‘rmse’ and a high R^squared mean of .93. Additionally, the standard errors are less than other models. The Random Forest Model uses the regression mode and ranger engine. It is preforming well for this problem because it handles the non linearity of streamflow well by modeling the interactions without them needing to be defined. It is also able to capture interactions between the input variables in my recipe. Lastly, the model is resistant to overfitting when compared to single models."
  },
  {
    "objectID": "hyperparameter-tuning.html#build-a-model-for-your-chosen-specifications",
    "href": "hyperparameter-tuning.html#build-a-model-for-your-chosen-specifications",
    "title": "Lab 8: Machine Learning Tuning",
    "section": "1. Build a model for your chosen specifications",
    "text": "1. Build a model for your chosen specifications\n\nlibrary(tidymodels)\n\nforest_model2 &lt;- rand_forest(\n  mtry = tune(),      \n  min_n = tune()\n) %&gt;%\n  set_engine(\"ranger\") %&gt;%\n  set_mode(\"regression\")"
  },
  {
    "objectID": "hyperparameter-tuning.html#create-a-workflow",
    "href": "hyperparameter-tuning.html#create-a-workflow",
    "title": "Lab 8: Machine Learning Tuning",
    "section": "2. Create a Workflow",
    "text": "2. Create a Workflow\n\nforest_wf2 &lt;- workflow() %&gt;%\n  add_recipe(flow_recipe2) %&gt;%\n  add_model(forest_model2)"
  },
  {
    "objectID": "hyperparameter-tuning.html#check-the-tunable-values-ranges",
    "href": "hyperparameter-tuning.html#check-the-tunable-values-ranges",
    "title": "Lab 8: Machine Learning Tuning",
    "section": "3. Check The Tunable Values / Ranges",
    "text": "3. Check The Tunable Values / Ranges\n\ndials &lt;- extract_parameter_set_dials(forest_wf2)\n\ndials\n\nCollection of 2 parameters for tuning\n\n\n\n\n\n identifier  type    object\n       mtry  mtry nparam[?]\n      min_n min_n nparam[+]\n\n\n\n\n\nModel parameters needing finalization:\n\n\n# Randomly Selected Predictors ('mtry')\n\n\n\n\n\nSee `?dials::finalize()` or `?dials::update.parameters()` for more information.\n\ndials$object\n\n[[1]]\n\n\n# Randomly Selected Predictors (quantitative)\n\n\nRange: [1, ?]\n\n\n\n[[2]]\n\n\nMinimal Node Size (quantitative)\n\n\nRange: [2, 40]"
  },
  {
    "objectID": "hyperparameter-tuning.html#define-the-search-space",
    "href": "hyperparameter-tuning.html#define-the-search-space",
    "title": "Lab 8: Machine Learning Tuning",
    "section": "4. Define the Search Space",
    "text": "4. Define the Search Space\n\ninstall.packages(\"dials\")\n\nWarning: package 'dials' is in use and will not be installed\n\nlibrary(dials)\nlibrary(tidymodels)\n\ndials_final &lt;- finalize(dials, flow_recipe2 %&gt;% prep() %&gt;% juice())\n\nmy.grid &lt;- grid_space_filling(\n  dials_final,\n  size = 25,\n  method = \"lhs\"\n)\n\nmy.grid\n\n# A tibble: 25 × 2\n    mtry min_n\n   &lt;int&gt; &lt;int&gt;\n 1     1    24\n 2     1    13\n 3     1    33\n 4     1     5\n 5     1    19\n 6     1    27\n 7     1    36\n 8     1    11\n 9     1     3\n10     2    21\n# ℹ 15 more rows"
  },
  {
    "objectID": "hyperparameter-tuning.html#tune-the-model",
    "href": "hyperparameter-tuning.html#tune-the-model",
    "title": "Lab 8: Machine Learning Tuning",
    "section": "5. Tune the Model",
    "text": "5. Tune the Model\n\nmodel_params &lt;-  tune_grid(\n    forest_wf2,\n    resamples = cam_cv,\n    grid = my.grid,\n    metrics = metric_set(rmse, rsq, mae),\n    control = control_grid(save_pred = TRUE)\n  )\n\n→ A | warning: ! 3 columns were requested but there were 2 predictors in the data.\n               ℹ 2 predictors will be used.\n\n\nThere were issues with some computations   A: x1\n\n\nThere were issues with some computations   A: x3\n\n\nThere were issues with some computations   A: x9\n\n\nThere were issues with some computations   A: x13\n\n\nThere were issues with some computations   A: x17\n\n\nThere were issues with some computations   A: x23\n\n\nThere were issues with some computations   A: x25\n\n\nThere were issues with some computations   A: x33\n\n\nThere were issues with some computations   A: x41\n\n\nThere were issues with some computations   A: x44\n\n\nThere were issues with some computations   A: x49\n\n\nThere were issues with some computations   A: x54\n\n\nThere were issues with some computations   A: x57\n\n\nThere were issues with some computations   A: x64\n\n\nThere were issues with some computations   A: x65\n\n\nThere were issues with some computations   A: x73\n\n\nThere were issues with some computations   A: x80\n\n\n\n\nautoplot(model_params)\n\n\n\n\n\n\n\n\nThe results of my autoplot visualization show how different combinations of my hyperparameters affect the random forest tree model performance. For the Y-axis performance metric, my mae error is lower with values closer to 0. My rmse performance metric is also low indicating a lower error. The rsq values are very close to 1 showing that the model’s predictions match the actual data well."
  },
  {
    "objectID": "hyperparameter-tuning.html#check-the-skill-of-the-tuned-model",
    "href": "hyperparameter-tuning.html#check-the-skill-of-the-tuned-model",
    "title": "Lab 8: Machine Learning Tuning",
    "section": "6. Check the skill of the tuned model",
    "text": "6. Check the skill of the tuned model\n\nmetrics_tuned &lt;- collect_metrics(model_params)\n\nmetrics_tuned\n\n# A tibble: 75 × 8\n    mtry min_n .metric .estimator  mean     n std_err .config              \n   &lt;int&gt; &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;                \n 1     1    24 mae     standard   0.283    10 0.0143  Preprocessor1_Model01\n 2     1    24 rmse    standard   0.479    10 0.0319  Preprocessor1_Model01\n 3     1    24 rsq     standard   0.914    10 0.00653 Preprocessor1_Model01\n 4     1    13 mae     standard   0.269    10 0.0135  Preprocessor1_Model02\n 5     1    13 rmse    standard   0.446    10 0.0277  Preprocessor1_Model02\n 6     1    13 rsq     standard   0.924    10 0.00676 Preprocessor1_Model02\n 7     1    33 mae     standard   0.295    10 0.0165  Preprocessor1_Model03\n 8     1    33 rmse    standard   0.508    10 0.0375  Preprocessor1_Model03\n 9     1    33 rsq     standard   0.903    10 0.00645 Preprocessor1_Model03\n10     1     5 mae     standard   0.269    10 0.0147  Preprocessor1_Model04\n# ℹ 65 more rows\n\n\nThe tibble shows a metric column that has the evaluation metric used, like rmse, rsq, or mae. There is a mean column that shows the average value of the metric for each set of hyperparameters. Which is the avg rmse, r squared, and mae across all cross-validation folds. n includes my chosen number of resamples which was set to be 10. There is also a std_error column showing the standard error of the metric and indicating how much variability there is in the performance across resamples.\n\nbest_mae &lt;- show_best(model_params, metric = \"mae\", n = 1)\n\nbest_mae\n\n# A tibble: 1 × 8\n   mtry min_n .metric .estimator  mean     n std_err .config              \n  &lt;int&gt; &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;                \n1     3    17 mae     standard   0.256    10  0.0118 Preprocessor1_Model19\n\n\nThe best model for Mean Absolute Error (mae) has the hyperparameters mtry = 2, the model considers 2 predictors at each split and min_n = 5 where the minimum number of observations required to make a split is 16. The avg mean for this hyperparameter combination is .256 which means that the model predictions are off by an average of .256 units from the actual values. The standard error is 0.116 meaning that the mae is very stable across the 10 resamples.\n\nhp_best &lt;- select_best(model_params, metric = \"mae\")\n\nhp_best\n\n# A tibble: 1 × 3\n   mtry min_n .config              \n  &lt;int&gt; &lt;int&gt; &lt;chr&gt;                \n1     3    17 Preprocessor1_Model19"
  },
  {
    "objectID": "hyperparameter-tuning.html#finalize-your-model",
    "href": "hyperparameter-tuning.html#finalize-your-model",
    "title": "Lab 8: Machine Learning Tuning",
    "section": "7. Finalize your model",
    "text": "7. Finalize your model\n\nfinal_wf &lt;- finalize_workflow(\n  forest_wf2,\n  hp_best\n)"
  }
]